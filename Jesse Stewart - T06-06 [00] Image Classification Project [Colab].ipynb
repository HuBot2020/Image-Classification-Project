{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Jesse Stewart - T06-06 [00] Image Classification Project [Colab].ipynb","version":"0.3.2","provenance":[{"file_id":"19brxoA1GgeDtmJJs36SJjM6IVvxHnYd7","timestamp":1560970997373}],"private_outputs":true,"collapsed_sections":["yFwKrxE38t9S"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yFwKrxE38t9S"},"source":["#### Copyright 2019 Google LLC."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kpcrMDk48nqI","colab":{}},"source":["# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bTZOeKjw8waH"},"source":["# Image Classification Project"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pK5j0BXxrbfX"},"source":["In this project, we will built an image classification model and use the model to identify if the image contain a particular object.  The outcome of the model will be true of false for each images."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7fz_1lEAXeW2"},"source":["## Overview"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lbXXnlHyXiKa"},"source":["### Learning Objectives\n","\n","* Use a classification toolkits (scikit-learn, TensorFlow, or Keras) and build an image classification model.\n","* Prepare image data to the appropriate format and quality to be a suitable input to the model."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"M62dLnxpX6Le"},"source":["### Prerequisites\n","\n","* Classification with scikit-learn\n","* Classification with TensorFlow\n","* Neural Networks\n","* Image Classificaion with Keras\n","* Image Manipulation with Python"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IrPi5LSZYIrw"},"source":["### Estimated Duration\n","\n","330 minutes (285 minutes working time, 45 minutes for presentations)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"r6RA-x2G2Fd4"},"source":["### Deliverables\n","\n","1. A copy of this Colab notebook containing your code and responses to the ethical considerations below. The code should produce a functional labeled video.\n","1. A group presentation. After everyone is done, we will ask each group to stand in front of the class and give a brief presentation about what they have done in this lab. The presentation can be a code walkthrough, a group discussion, a slide show, or any other means that conveys what you did over the course of the day and what you learned. If you do create any artifacts for your presentation, please share them in the class folder."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pzCWjL4DYLgf"},"source":["### Grading Criteria\n","\n","This project is graded in separate sections that each contribute a percentage of the total score:\n","\n","1. Building and Using a Model (80%)\n","1. Ethical Implications (10%)\n","1. Project Presentation (10%)\n","\n","#### Building and Using a Model\n","\n","There are 6 demonstrations of competency listed in the problem statement below. Each competency is graded on a 3 point scale for a total of 18 available points. The following rubric will be used:\n","\n","| Points | Description |\n","|--------|-------------|\n","| 0      | No attempt at the competency |\n","| 1      | Attempted competency, but in an incorrect manner |\n","| 2      | Attempted competency correctly, but sub-optimally |\n","| 3      | Successful demonstration of competency |\n","\n","\n","#### Ethical Implications\n","\n","There are six questions in the **Ethical Implications** secion. Each question is worth 2 points. The rubric for calculating those points is:\n","\n","| Points | Description |\n","|--------|-------------|\n","| 0      | No attempt at question or answer was off-topic or didn't make sense |\n","| 1      | Question was answered, but answer missed important considerations  |\n","| 2      | Answer adequately considered ethical implications |\n","\n","#### Project Presentation\n","\n","The project presentation will be graded on participation. All members of a team should actively participate."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_yACB56w2JVk"},"source":["## Team\n","\n","Please enter your team members names in the placeholders in this text area:\n","\n","*   Jesse\n","*   Qianti\n","*   Michael\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YTVUYxPwcHhp"},"source":["# Exercises"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LdIOgOHP1ces"},"source":["## Exercise 1: Coding"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jhTEOK1ZmqN8"},"source":["There are very few more important questions in life than \"[Hot dog or not hot dog?](https://www.youtube.com/watch?v=ACmydtFDTGs)\". For this workshop you will be tasked with creating a machine learning model that can **take an input image and determine if the image is of a hot dog or not a hot dog**.\n","\n","Train your model with the [Kaggle Hot Dog/Not Hot Dog](https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog/data) data set. Feel free to [do some background research](https://medium.com/@timanglade/how-hbos-silicon-valley-built-not-hotdog-with-mobile-tensorflow-keras-react-native-ef03260747f3) on the topic.\n","\n","We have looked at regression, classification, and clustering models. We have used the Scikit Learn, TensorFlow, and Keras toolkits. Feel free to use the model and toolkit that you feel is the most appropriate.\n"," \n","**Graded** demonstrations of competency:\n","1. Pick a classification toolkit (eg: scikit-learn, TensorFlow or Keras) and provide jusitifaction for your choice. \n","1. Obtain, prepare and load the dataset.\n","1. Define and train a classification model.\n","1. Test and evaluation your classification model. \n","1. Apply your classification model to an image sourced from outside the Kaggle dataset. \n","1. Test multiple models and/or sets of hyper-parameters and record the results. \n","  \n","Some tips:\n"," \n","* Think about how to pre-process the images prior to use them as training data.  Should you train with images in color or grayscale, how many pixels should the image contains, etc. Clearly explain the reasoning for all of your choices in your Colab. \n"," "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7XM35vYWSbim"},"source":["### Student Solution"]},{"cell_type":"code","metadata":{"id":"DOvmTc0yKOMw","colab_type":"code","colab":{}},"source":["import zipfile\n","zip_ref = zipfile.ZipFile('hot-dog-not-hot-dog.zip', 'r')\n","zip_ref.extractall('./')\n","zip_ref.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t2SJulkRKO0V","colab_type":"code","colab":{}},"source":["import cv2 as cv\n","import glob as gb\n","import matplotlib.pyplot as plt\n","\n","\n","filenames = gb.glob(\"train/hot_dog/*.jpg\")\n","train_imgs = [cv.imread(img) for img in filenames]\n","\n","filenames = gb.glob(\"train/not_hot_dog/*.jpg\")\n","train_not_imgs = [cv.imread(img) for img in filenames]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"25nl4OqtKQz0","colab_type":"code","colab":{}},"source":["#augment data for hot_dog images using keras\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","\n","datagen = ImageDataGenerator(\n","        rotation_range=40,\n","        width_shift_range=0.2,\n","        height_shift_range=0.2,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True,\n","        fill_mode='nearest')\n","\n","#reshape images to be fed into keras datagen\n","for _ in range(len(train_imgs)):\n","  train_imgs[_] = train_imgs[_].reshape((1,) + train_imgs[_].shape)\n","  \n","i = 0\n","for j in range(len(train_imgs)):\n","  \n","  for batch in datagen.flow(train_imgs[j], batch_size=1,\n","                            save_to_dir='train/hot_dog', save_prefix='rand', save_format='jpg'):\n","    i += 1\n","    if i > 4:\n","      break "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NSIncLGwKTtS","colab_type":"code","colab":{}},"source":["#augment data for not_hot_dog images using keras\n","for _ in range(len(train_not_imgs)):\n","  train_not_imgs[_] = train_not_imgs[_].reshape((1,) + train_not_imgs[_].shape)\n","  \n","i = 0\n","for j in range(len(train_not_imgs)):\n","  \n","  for batch in datagen.flow(train_not_imgs[j], batch_size=1,\n","                            save_to_dir='train/not_hot_dog', save_prefix='rand', save_format='jpg'):\n","    i += 1\n","    if i > 4:\n","      break "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gld8NTQwjJ7Y","colab_type":"code","colab":{}},"source":["import cv2 as cv\n","import glob as gb\n","import matplotlib.pyplot as plt\n","  \n","filenames = gb.glob(\"train/hot_dog/*.jpg\")\n","train_hot = [cv.imread(img) for img in filenames]\n","\n","filenames = gb.glob(\"train/not_hot_dog/*.jpg\")\n","train_not = [cv.imread(img) for img in filenames]\n","\n","filenames = gb.glob(\"test/hot_dog/*.jpg\")\n","test_hot = [cv.imread(img) for img in filenames]\n","\n","filenames = gb.glob(\"test/not_hot_dog/*.jpg\")\n","test_not = [cv.imread(img) for img in filenames]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8y1ziGgtnEX_","colab_type":"code","colab":{}},"source":["train_hot = [cv.cvtColor(img, cv.COLOR_BGR2GRAY) for img in train_hot]\n","train_not = [cv.cvtColor(img, cv.COLOR_BGR2GRAY) for img in train_not]\n","test_hot = [cv.cvtColor(img, cv.COLOR_BGR2GRAY) for img in test_hot]\n","test_not = [cv.cvtColor(img, cv.COLOR_BGR2GRAY) for img in test_not]\n","\n","train_hot = [cv.resize(img, (100, 100)) for img in train_hot] #<---- these were originally 40,40\n","train_not = [cv.resize(img, (100, 100)) for img in train_not]\n","test_hot = [cv.resize(img, (100, 100)) for img in test_hot]\n","test_not = [cv.resize(img, (100, 100)) for img in test_not]\n","\n","train_hot = [img.reshape(-1) for img in train_hot]\n","train_not = [img.reshape(-1) for img in train_not]\n","test_hot = [img.reshape(-1) for img in test_hot]\n","test_not = [img.reshape(-1) for img in test_not]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gh4-jtObrVXq","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","hotdog_images = np.array([i.reshape(100,100) for i in train_hot])\n","notdog_images = np.array([i.reshape(100,100) for i in train_not])\n","train_images = np.concatenate((hotdog_images, notdog_images))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mUU4ERCs4NhO","colab_type":"code","colab":{}},"source":["print(hotdog_images.shape)\n","print(notdog_images.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RFI_KAL-sYv1","colab_type":"code","colab":{}},"source":["train_labels = [1] * 498 + [0] * 498\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_omfZjyNlg1k","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","\n","train_df = pd.DataFrame(train_hot)\n","train_df_not = pd.DataFrame(train_not)\n","\n","test_df = pd.DataFrame(test_hot)\n","test_df_not = pd.DataFrame(test_not)\n","\n","train_df['hot_dog'] = np.ones(len(train_hot), dtype=int)\n","train_df_not['hot_dog'] = np.zeros(len(train_not), dtype=int)\n","\n","train_df = pd.concat([train_df, train_df_not], axis=0, sort=True)\n","train_df = train_df.reset_index(drop=True)\n","\n","test_df['hot_dog'] = np.ones(len(test_hot), dtype=int)\n","test_df_not['hot_dog'] = np.zeros(len(test_not), dtype=int)\n","\n","test_df = pd.concat([test_df, test_df_not], axis=0, sort=True)\n","test_df = test_df.reset_index(drop=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A193AaLANyAQ","colab_type":"text"},"source":["#Neural Networks in Scikit-learn"]},{"cell_type":"code","metadata":{"id":"RCtcOpeBVJya","colab_type":"code","colab":{}},"source":["from sklearn.neural_network import MLPClassifier \n","clf = MLPClassifier(activation='relu', solver='adam',\n","                     hidden_layer_sizes=(20, 20), random_state=4321)\n","\n","clf.fit(np.array(train_df.iloc[:,0:-1]), np.array(train_df.iloc[:,-1])) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ZmB3BlYW9mi","colab_type":"code","colab":{}},"source":["from sklearn import metrics\n","from sklearn import model_selection\n","\n","scores = model_selection.cross_val_predict(\n","  clf, \n","  np.array(test_df.iloc[:,0:-1]),\n","  np.array(test_df.iloc[:,-1]),\n","  cv=3\n",")\n","\n","precisions, recalls, thresholds = metrics.precision_recall_curve(\n","  np.array(test_df.iloc[:,-1]),\n","  scores\n",")\n","\n","plt.plot(thresholds, precisions[:-1], \"g--\", label=\"Precision\")\n","plt.plot(thresholds, recalls[:-1], \"r-\", label=\"Recall\")\n","plt.xlabel(\"Threshold\")\n","plt.legend(loc=\"upper right\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JX7qu8YxVrny","colab_type":"code","colab":{}},"source":["predictions = clf.predict(test_df.iloc[:, 0:-1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8uBWAnDYLoi","colab_type":"code","colab":{}},"source":["accuracy = metrics.accuracy_score(test_df.iloc[:,-1], predictions)\n","accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S_Bjk0KPi8S3","colab_type":"text"},"source":["**Results for Scikit Learn Multi-Layer Perceptron:**\n","\n","Recall: *approx* .52\n","\n","Precision: *approx* .65\n","\n","Accuracy: 0.5\n","\n","Note: Recall and Precision are read from the graph at threshold of 0.7. "]},{"cell_type":"markdown","metadata":{"id":"HvsZP8efcHU-","colab_type":"text"},"source":["#Neural Network in Keras"]},{"cell_type":"markdown","metadata":{"id":"c-aisZwwOUpi","colab_type":"text"},"source":["We attempted 4 trials to try and find the ideal neural network model. The code shows the last trial used. But the results of each are shown at the bottom of this section. We varied number of hidden layers, number of neurons, and optimizer used."]},{"cell_type":"code","metadata":{"id":"XvjQod2gmSyY","colab_type":"code","colab":{}},"source":["kerasTrain = train_df\n","# kerasTrain.iloc[:,0:-1] = kerasTrain.iloc[:,0:-1] / 255.0\n","\n","kerasTest = test_df\n","# kerasTest.iloc[:,0:-1] = kerasTest.iloc[:,0:-1] / 255.0\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g-lmFxhoMBos","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","\n","model = tf.keras.Sequential([\n","    \n","    # Layer 1\n","    tf.keras.layers.Flatten(input_shape=(10000,)),\n","    \n","    # Layer 2\n","    tf.keras.layers.Dense(100, activation=tf.nn.relu), \n","    #Layer 3\n","    tf.keras.layers.Dense(100, activation=tf.nn.relu),\n","    \n","    # Layer 4\n","    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ARDqosRqNxGD","colab_type":"code","colab":{}},"source":["# Set model's settings, including loss function, optimizer, and metrics\n","\n","model.compile(\n","    \n","    # Specify loss function\n","    \n","    loss='binary_crossentropy',\n","    \n","    # Specify optimizer\n","    optimizer='adam',\n","    \n","    # Specify metrics\n","    metrics=['accuracy']\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eRUtfmXIN7Bo","colab_type":"code","colab":{}},"source":["# Start model training\n","\n","\n","history = model.fit(kerasTrain.iloc[:,0:-1], kerasTrain.iloc[:,-1], epochs=15)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gfVa9JijiWlv","colab_type":"code","colab":{}},"source":["# Set the overall dimension of the chart area\n","\n","plt.figure(figsize=(16,5))\n","\n","# Set plot to go to first grid of a 1x2 grid\n","\n","plt.subplot(1,2,1)\n","\n","# Plot training set accuracy values for each training iteration\n","\n","plt.plot(history.history['acc'])\n","plt.title('Training Accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train_accuracy'], loc='best')\n","\n","# Set subplot to go to second grid of a 1x2 grid\n","\n","plt.subplot(1,2,2)\n","\n","# Plot training set loss values for each training iteration\n","\n","plt.plot(history.history['loss'])\n","plt.title('Training Loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train_loss'], loc='best')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yWE5EAP4v-zY","colab_type":"code","colab":{}},"source":["probability = model.predict(kerasTest.iloc[:, 0:-1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMLJG26Xwrmf","colab_type":"code","colab":{}},"source":["y_pred = []\n","threshold = 0.7\n","\n","for i in probability:\n","  if i > threshold:\n","    y_pred.append(1)\n","  else:\n","    y_pred.append(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"50YeQd6evanj","colab_type":"code","colab":{}},"source":["from sklearn import metrics\n","from sklearn import model_selection\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import accuracy_score\n","\n","print(\"recall: {}\".format(recall_score(kerasTest.iloc[:,-1], y_pred)))\n","print(\"precision: {}\".format(precision_score(kerasTest.iloc[:, -1], y_pred)))\n","print(\"accuracy: {}\".format(accuracy_score(kerasTest.iloc[:,-1], y_pred)))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZOCUCUHoiaxY","colab_type":"code","colab":{}},"source":["# Use test dataset to evaluate model accuracy\n","\n","# (test_loss, test_acc) = model.evaluate(kerasTest.iloc[:,0:-1], kerasTest.iloc[:,-1])\n","\n","# print('Test accuracy:', test_acc)\n","# #print('Test loss:', test_loss)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9x5aIi1YN8hj","colab_type":"text"},"source":["**Using Leaky Relu in 1 hidden layer (100) and adam optimizer:**\n","\n","recall: 0.02\n","\n","precision: 0.5555555555555556\n","\n","accuracy: 0.502"]},{"cell_type":"markdown","metadata":{"id":"ZXk4n1P_Om3W","colab_type":"text"},"source":["**Using Leaky Relu in two hidden layers (128, 10) and adagrad optimizer:**\n","\n","recall: 0.168\n","\n","precision: 0.5526315789473685\n","\n","accuracy: 0.516"]},{"cell_type":"markdown","metadata":{"id":"9JmoK73jPTDp","colab_type":"text"},"source":["**Using Relu in two hidden layers (128, 10) and adam optimizer:**\n","\n","recall: 0.604\n","\n","precision: 0.5261324041811847\n","\n","accuracy: 0.53"]},{"cell_type":"markdown","metadata":{"id":"oOYxImxqPzCc","colab_type":"text"},"source":["**Using Relu in two hidden layers (100,100) and adam optimizer:**\n","\n","recall: 0.036\n","\n","precision: 0.75\n","\n","accuracy: 0.512"]},{"cell_type":"markdown","metadata":{"id":"D2E4GYMGLa2y","colab_type":"text"},"source":["#Binary Classifier"]},{"cell_type":"code","metadata":{"id":"8lyUSTSQRykP","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","train, test = train_test_split(\n","  train_df,                    \n","  stratify=train_df['hot_dog'],\n","  shuffle=True,\n","  test_size=0.2\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8aa79-Po5kOJ","colab_type":"code","colab":{}},"source":["from sklearn import linear_model\n","\n","binary_classifier = linear_model.SGDClassifier(\n","  tol=1e-3, \n","  max_iter=500) \n"," \n","binary_classifier.fit(train[train.columns[0:1599]], train['hot_dog'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TPtD6PO3GU1U","colab_type":"code","colab":{}},"source":["from sklearn import metrics\n","from sklearn import model_selection\n","\n","scores = model_selection.cross_val_predict(\n","  binary_classifier, \n","  test[test.columns[0:1599]],\n","  test['hot_dog'],\n","  cv=3,\n","  method=\"decision_function\"\n",")\n","\n","precisions, recalls, thresholds = metrics.precision_recall_curve(\n","  test['hot_dog'],\n","  scores\n",")\n","\n","plt.plot(thresholds, precisions[:-1], \"g--\", label=\"Precision\")\n","plt.plot(thresholds, recalls[:-1], \"r-\", label=\"Recall\")\n","plt.xlabel(\"Threshold\")\n","plt.legend(loc=\"upper right\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xnbmHksHA9e","colab_type":"code","colab":{}},"source":["threshold = -1\n","predictions = (scores > threshold)\n","\n","accuracy = metrics.accuracy_score(test['hot_dog'], predictions)\n","precision = metrics.precision_score(test['hot_dog'], predictions)\n","recall = metrics.recall_score(test['hot_dog'], predictions)\n","\n","print(\"Precision: {}\\nRecall: {}\".format(precision, recall))\n","print(\"Accuracy: {}\".format(accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t-jwGQWLQDgE","colab_type":"text"},"source":["**Binary Classifier Results: **\n","\n","Precision: 0.47413793103448276\n","\n","Recall: 0.55\n","\n","Accuracy: 0.47"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HniKdSXg0YHR"},"source":["## Exercise 2: Ethical Implications (OPTIONAL)\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"W4FvC1Aa0ZT5"},"source":["Even the most basic of models have the potential to affect segments of the population in different ways. It is important to consider how your model might positively and negative effect different types of users.\n","\n","In this section of the project you will reflect on the positive and negative implications of your model.\n","\n","Frame the context of your models creation using this narriative:\n","\n","  > The city of Seattle is attempting to reduce traffic congestion in their downtown area. As part of this project, they plan on allowing each local driver one free downtown trip per week. After that the driver will have to pay a $50 toll for each extra day per week driven. As an early proof-of-concept for this project your team is tasked with using machine learning to correctly identify automobiles on the road. The next phase of the project will involve detecting license plate numbers and then cross-referencing that data with RFID chips that should be mounted in all local drivers cars."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lkyzwVQr0brd"},"source":["### Student Solution"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gy4I2vG60ebd"},"source":["**Positive Impact**\n","\n","Your model is trying to solve a problem. Think about who will benefit from that problem being solved and write a brief narrative about how the model will help.\n","\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k59MK1Ah0fWy"},"source":["*Hypothetical entities will benefit because...*"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gzqkrLnk0hMU"},"source":["**Negative Impact**\n","\n","Models don't often have universal benefit. Think about who might be negatively impacted by the predictions your model is making. This person or persons might not be directly using the model, but instead might be impacted indirectly.\n","\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Hefa1JdP0kj3"},"source":["*Hypothetical entity will be negatively impacted because...*"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Uax2HAzd0mHX"},"source":["**Bias**\n","\n","Models can be bias for many reasons. The bias can come from the data used to build the model (eg. sampling, data collection methods, available sources) and from the interpretation of the predictions generated by the model.\n","\n","Think of at least two ways that bias might have been introduced to your model and explain both below.\n","\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6bJGm-qs0oQV"},"source":["*One source of bias in the model could be...*\n","\n","*Another source of bias in the model could be...*"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ybb1zAkC0p2e"},"source":["**Changing the Dataset to Mitigate Bias**\n","\n","Bias datasets are one of the primary ways in which bias is introduced to a machine learning model. Look back at the input data that you fed to your model. Think about how you might change something about the data to reduce bias in your model.\n","\n","What change or changes could you make to your dataset less bias? Consider the data that you have, how and where that data was collected, and what other sources of data might be used to reduce bias.\n","\n","Write a summary of change that could be made to your input data.\n","\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UFsnF4_h08DD"},"source":["*Since the data has potential bias A we can adjust...*"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ChEJbhXA02pW"},"source":["**Changing the Model to Mitigate Bias**\n","\n","Is there any way to reduce bias by changing the model itself? This could include modifying algorithmic choices, tweaking hyperparameters, etc.\n","\n","Write a brief summary of changes that you could make to help reduce bias in your model.\n","\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kEAhgO_U0p8Y"},"source":["*Since the model has potential bias A we can adjust...*"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rShB5BQv0wix"},"source":["**Mitigating Bias Downstream**\n","\n","Models make predictions. Downstream processes make decisions. What processes and/or rules should be in place for people and systems interpreting and acting on the results of your model to reduce the bias? Describe these below.\n","\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"C__BwBP-00HN"},"source":["*Since the predictions have potential bias A we can adjust...*"]}]}